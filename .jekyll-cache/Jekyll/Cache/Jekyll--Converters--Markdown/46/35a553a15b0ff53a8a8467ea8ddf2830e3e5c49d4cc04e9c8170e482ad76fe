I"0+<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

<h5 id="abstract">Abstract</h5>

<p>The phenomenon of ellipsis is prevalent in social conversations. Ellipsis increases the difficulty of a series of downstream language understanding tasks, such as dialog act prediction and semantic role labeling. We propose to resolve ellipsis through automatic sentence completion to improve language understanding. However, automatic ellipsis completion can result in output which does not accurately reflect user intent. To address this issue, we propose a method which considers both the original utterance that has ellipsis and the automatically completed utterance in dialog act and semantic role labeling tasks. Specifically, we first complete user utterances to resolve ellipsis using an
end-to-end pointer network model. We then train a prediction model using both
utterances containing ellipsis and our automatically completed utterances.
Finally, we combine the prediction results from these two utterances using a
selection model that is guided by expert knowledge. Our approach improves dialog act prediction and semantic role labeling by 1.3% and 2.5% in F1 score
respectively in social conversations. We also present an open-domain
human-machine conversation dataset with manually completed user utterances and annotated semantic role labeling after manual completion.</p>

<h5 id="motivation">Motivation</h5>

<p>Ellipsis, in which a speaker omits words that are understood from context, is a frequent phenomenon in human conversation. Although natural to humans, ellipsis poses a challenge for language understanding in spoken dialog systems.</p>

<p>A possible way to resolve semantic ambiguity caused by ellipsis is to train a model that can automatically complete sentences with ellipsis.</p>

<p>However, automatic completion may introduce errors that can lead to other misunderstandings in downstream tasks. To mitigate the impact of such completion errors, we propose a hybrid framework that considers both utterances with ellipsis and their automatically completed counterparts.</p>

<p>Here are examples of dialog act predication:</p>

<figure class="image">
  <img src="./AAAI2020/example.png" alt="" style="width: 50%" />
  <figcaption><b></b></figcaption>
</figure>

<p>Here are examples of semantic role labeling:</p>

<figure class="image">
  <img src="./AAAI2020/example_srl.png" alt="" style="width: 50%" />
  <figcaption><b></b></figcaption>
</figure>

<h5 id="proposed-model">Proposed Model</h5>

<figure class="image">
  <img src="./AAAI2020/model.png" alt="" style="width: 100%" />
  <figcaption><b></b></figcaption>
</figure>

<p><strong>Completion Model</strong></p>

<p>Our completion model is based on Pointer Generator (Vinyals, Fortunato, and Jaitly 2015; Gu et al. 2016; See, Liu, and Manning 2017) which allows copying words directly from the context (previous user utterances in our case) while retaining the ability to generate words from the decoder. These copied words are likely to be the omitted information that we want to complete. Here we use <script type="math/tex">\lambda</script> to represent a switch probability between generation mode and copy mode, which is calculated from the encoder context vector $h_t$, the decoder input $x_t$ and the decoder hidden states $s_t$ at time step $t$:
<script type="math/tex">\begin{eqnarray}
	\lambda = sigmoid(W_\lambda[h^*,x_t,s_t]+b_\lambda)
\end{eqnarray}</script>
We use $P(\omega)$ to represent the distribution over the whole vocabulary to get the word $\omega$ from the decoder.
<script type="math/tex">% <![CDATA[
\begin{eqnarray*}
&P_{gen}(\omega)& = g(h^*,s_t) \tag{1}\\
&P_{copy}(\omega)& = \sum_ia_i^t \tag{2}\\
&P(\omega)& = softmax([\lambda P_{gen}(\omega),(1-\lambda)P_{copy}(\omega)]) \tag{3}\\
\end{eqnarray*} %]]></script>
<strong>Language Understanding Model</strong></p>

<p>We have two encoder-classifier models: the model above is for encoding utterances with ellipsis and the model below is for encoding utterances after completion.</p>

<ul>
  <li>For dialog act prediction, we leverage the BERT model trained on Wikipedia (Devlin et al.2018)</li>
  <li>For semantic role labeling, we leverage stacked Bi-LSTMs with highway connections trained on CONLL2012 (Pradhan et al. 2012), similar to (He et al. 2017).</li>
</ul>

<p><strong>Selection Model</strong></p>

<p>We experiment with several selection methods to combine the information of utterances with ellipsis and utterances after completion.</p>

<ul>
  <li><strong>Logits-based methods</strong>:</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}
D_{sum}& = &D_E+D_C \tag{4}\\
D_{max}& = &max(D_E,D_C) \tag{5}\\
\end{eqnarray} %]]></script>

<ul>
  <li><strong>Hidden-states-based methods</strong>:</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}
H_{sum}& = &H_E+H_C \tag{6}\\
H_{max}& = &max(H_E,H_C) \tag{7}\\
H_{cat}& = &[H_E|H_C] \tag{8} \\
D& = &W * H+b \tag{9}
\end{eqnarray} %]]></script>

<ul>
  <li><strong>Expert knowledge</strong></li>
</ul>

<p>Dialog act prediction Model:</p>

<p>We define specific dialog acts that are not suitable to be predicted from complete utterances (e.g. hold)</p>

<p>SRL Model:</p>

<p><em>Rule-based Method:</em> Choose predictions from the original utterance if the original utterance has a predicate</p>

<p><em>Probability-based-based Method:</em> For a specific argument, choose predictions from the auto-completed utterance with some probability even if the original utterance has a predicate. This probability is related to the beam search posterior probability for this argument in the completion model.</p>

<h5 id="annotation-scheme-and-datasets">Annotation Scheme and Datasets</h5>

<p>Our dataset is collected in our in-lab user studies with a social bot on the Alexa platform (Gunrock dataset) (Chen et al. 2018a). It consists of real human-machine social conversations that cover a broad range of topics including sports, politics, entertainment, technology, etc.</p>

<p><strong>Utterance Completion Scheme</strong></p>

<p>The original utterances are completed following these rules:</p>

<ul>
  <li>If the original utterance has ellipsis, then we manually complete the utterance</li>
  <li>If the original utterance is complete and may be readily modified to create an example of ellipsis , then we modify the utterance to create a version containing ellipsis</li>
  <li>If the utterance is complete and not appropriate for creating an ellipsis version, we just keep the original utterance.</li>
</ul>

<p><strong>Dialog Act Annotation Scheme</strong></p>

<p>The annotation of dialog act dataset follows the scheme of MIDAS (Yu and Yu 2019). We have totally annotated 11,602 user utterances with 23 dialog acts</p>

<p><strong>Semantic Role Labeling Scheme</strong></p>

<p>The format of dataset follows the scheme of CONLLU2012 and  the semantic role labeling annotation follows the “English PropBank Annotation Guidelines”. We have totally annotated 1,689 user utterances.</p>

<figure class="image">
  <img src="./AAAI2020/annotation_srl.png" alt="" style="width: 100%" />
  <figcaption><b></b></figcaption>
</figure>

<h5 id="experimental-results">Experimental Results</h5>

<p>Our approach improves dialog act prediction and semantic role labeling by 1.3% and 2.5% in F1 score respectively in social conversations. For further analysis of dialog act prediction and SRL:</p>

<table>
  <thead>
    <tr>
      <th>Notations</th>
      <th style="text-align: left">Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>EL</td>
      <td style="text-align: left">a single model trained on utterances with ellipsis</td>
    </tr>
    <tr>
      <td>CMP</td>
      <td style="text-align: left">a single model trained on utterances after completion</td>
    </tr>
    <tr>
      <td>Hybrid-EL-EL</td>
      <td style="text-align: left">two models both trained on utterances with ellipsis</td>
    </tr>
    <tr>
      <td>Hybrid-CMP-CMP</td>
      <td style="text-align: left">two models both trained on utterances after completion</td>
    </tr>
    <tr>
      <td>Hybrid-EL-CMP</td>
      <td style="text-align: left">the proposed model, one trained on utterances with ellipsis and the other trained on utterances after completion</td>
    </tr>
    <tr>
      <td>Hybrid-EL-CMP1</td>
      <td style="text-align: left">the proposed model with rule-based prediction output</td>
    </tr>
    <tr>
      <td>Hybrid-EL-CMP2</td>
      <td style="text-align: left">the proposed model with probability-based prediction output</td>
    </tr>
  </tbody>
</table>

<p><strong>Dialog act prediction</strong></p>

<p>Table 5 shows that Hybrid-EL-CMP performs the best in dialog act prediction</p>

<figure class="image">
  <img src="./AAAI2020/res_da.png" alt="" style="width: 50%" />
  <figcaption><b></b></figcaption>
</figure>

<p>Table 6 shows the dialog act prediction performance using different selection methods.</p>

<figure class="image">
  <img src="./AAAI2020/ablation.png" alt="" style="width: 50%" />
  <figcaption><b></b></figcaption>
</figure>

<p>We show here some case studies of dialog act prediction task. The first two lines show cases when original utterances predict the incorrect dialog acts while auto-complete utterances predict correct dialog acts. The last two lines are reversed. In all four cases, our Hybrid-EL-CMP predicts the correct dialog acts. Italics represents the automatically completed part.</p>

<figure class="image">
  <img src="./AAAI2020/case_da.png" alt="" style="width: 100%" />
  <figcaption><b></b></figcaption>
</figure>

<p><strong>Semantic role labeling</strong></p>

<p>Table 8 shows that Hybrid-EL-CMP2 gets the highest F1 score. But there are cases when Hybrid-EL-CMP1 beats Hybrid-EL-CMP2, and vice versa.</p>

<figure class="image">
  <img src="./AAAI2020/res_srl.png" alt="" style="width: 50%" />
  <figcaption><b></b></figcaption>
</figure>

<h5 id="conclusion">Conclusion</h5>

<p>Ellipsis frequently occurs in social conversations. We propose
Hybrid-ELlipsis-CoMPlete (Hybrid-EL-CMP) to utilize both original utterances with ellipsis and their automatically completed counterparts for improving language understanding in human-machine social conversations. We show the effectiveness of the proposed approach on language understanding tasks by evaluating on dialog act prediction and semantic role labeling. We believe that the framework can be generalized to other dialog understanding tasks as well, such as syntactic and semantic parsing. We will evaluate these tasks and also our proposed model on other domains such as human-human conversations in the future.</p>
:ET